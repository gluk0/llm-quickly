from pydantic import BaseModel
from typing import Optional

class InferenceRequest(BaseModel):
    """
    Schema for inference request payload.
    
    Attributes:
        prompt: Input text for the model
        max_length: Maximum length of generated text
        temperature: Sampling temperature for generation
        top_p: Top-p sampling parameter
    """
    prompt: str
    max_length: Optional[int] = 100
    temperature: Optional[float] = 0.7
    top_p: Optional[float] = 0.9

class InferenceResponse(BaseModel):
    """
    Schema for inference response.
    
    Attributes:
        generated_text: Text generated by the model
    """
    generated_text: str 